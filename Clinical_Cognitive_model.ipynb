{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.5)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/samylokanandi/Library/Python/3.12/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samylokanandi/Library/Python/3.12/lib/python/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samylokanandi/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy matplotlib scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final merged shape: (4335, 22)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"PPMI_ds/\"\n",
    "\n",
    "files = {\n",
    "    \"diagnosis\": \"Primary_Clinical_Diagnosis_18Mar2025.csv\",\n",
    "    \"parkinsonism\": \"Features_of_Parkinsonism_18Mar2025.csv\",\n",
    "    \"rem\": \"Features_of_REM_Behavior_Disorder_18Mar2025.csv\",\n",
    "    \"cgi\": \"Clinical_Global_Impression__CGI__-_Investigator_18Mar2025.csv\",\n",
    "    \"exam\": \"General_Physical_Exam_18Mar2025.csv\"\n",
    "}\n",
    "\n",
    "dfs = {name: pd.read_csv(f\"{data_dir}/{fname}\") for name, fname in files.items()}\n",
    "\n",
    "# ðŸ”¹ Step 2: Clean general physical exam (pivot long format)\n",
    "exam_df = dfs['exam'][['PATNO', 'PECAT', 'ABNORM']]\n",
    "exam_wide = exam_df.pivot_table(index='PATNO', columns='PECAT', values='ABNORM', aggfunc='max')\n",
    "exam_wide.columns = [f\"ABNORM_{str(col).strip().replace(' ', '_')}\" for col in exam_wide.columns]\n",
    "exam_wide.reset_index(inplace=True)\n",
    "\n",
    "# ðŸ”¹ Step 3: Prepare label (PRIMDIAG from diagnosis file)\n",
    "label_df = dfs['diagnosis'][['PATNO', 'PRIMDIAG']].drop_duplicates(subset='PATNO')\n",
    "label_df['label'] = label_df['PRIMDIAG'].apply(lambda x: 1 if x == 17 else 0)\n",
    "label_df = label_df[['PATNO', 'label']]\n",
    "\n",
    "# ðŸ”¹ Step 4: Process and aggregate other files (1 row per PATNO)\n",
    "aggregated = []\n",
    "\n",
    "for key in ['parkinsonism', 'rem', 'cgi']:\n",
    "    df = dfs[key]\n",
    "    df = df.drop(columns=[col for col in df.columns if col in ['EVENT_ID', 'INFODT', 'REC_ID', 'PAG_NAME', 'ORIG_ENTRY', 'LAST_UPDATE']], errors='ignore')\n",
    "    df_grouped = df.groupby('PATNO').mean(numeric_only=True).reset_index()\n",
    "    aggregated.append(df_grouped)\n",
    "\n",
    "# ðŸ”¹ Step 5: Merge everything into one DataFrame\n",
    "merged = label_df.copy()\n",
    "\n",
    "for df in aggregated + [exam_wide]:\n",
    "    merged = merged.merge(df, on='PATNO', how='left')\n",
    "\n",
    "print(\"âœ… Final merged shape:\", merged.shape)\n",
    "merged.to_csv(\"merged_clin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X = merged.drop(columns=['PATNO', 'label'])\n",
    "y = merged['label']\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, stratify=y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Logistic Regression\n",
      "âœ… Accuracy: 0.76239907727797\n",
      "ðŸ“ˆ ROC AUC: 0.8476518394441342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82       597\n",
      "           1       0.61      0.67      0.64       270\n",
      "\n",
      "    accuracy                           0.76       867\n",
      "   macro avg       0.73      0.74      0.73       867\n",
      "weighted avg       0.77      0.76      0.77       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_pred = logreg.predict(X_test)\n",
    "logreg_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ðŸ”¹ Logistic Regression\")\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
    "print(\"ðŸ“ˆ ROC AUC:\", roc_auc_score(y_test, logreg_proba))\n",
    "print(classification_report(y_test, logreg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Random Forest\n",
      "âœ… Accuracy: 0.8050749711649365\n",
      "ðŸ“ˆ ROC AUC: 0.8724145418450276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       597\n",
      "           1       0.68      0.69      0.69       270\n",
      "\n",
      "    accuracy                           0.81       867\n",
      "   macro avg       0.77      0.77      0.77       867\n",
      "weighted avg       0.81      0.81      0.81       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nðŸ”¹ Random Forest\")\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(\"ðŸ“ˆ ROC AUC:\", roc_auc_score(y_test, rf_proba))\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ MLP Neural Network\n",
      "âœ… Accuracy: 0.7889273356401384\n",
      "ðŸ“ˆ ROC AUC: 0.8450586264656615\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       597\n",
      "           1       0.65      0.70      0.67       270\n",
      "\n",
      "    accuracy                           0.79       867\n",
      "   macro avg       0.75      0.77      0.76       867\n",
      "weighted avg       0.79      0.79      0.79       867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "mlp_proba = mlp.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nðŸ”¹ MLP Neural Network\")\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_test, mlp_pred))\n",
    "print(\"ðŸ“ˆ ROC AUC:\", roc_auc_score(y_test, mlp_proba))\n",
    "print(classification_report(y_test, mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the y_test from previous context for class distribution\n",
    "# For demo, assume y contains the full label array\n",
    "\n",
    "# Simulate what y would look like\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Reconstruct y as binary just for visualization\n",
    "# Normally you'd pass your actual y Series here\n",
    "# Assuming we already have 'y' from your session\n",
    "try:\n",
    "    label_counts = Counter(y)\n",
    "except NameError:\n",
    "    label_counts = Counter(y)\n",
    "\n",
    "labels = ['Healthy Control', 'PD']\n",
    "counts = [label_counts[0], label_counts[1]]\n",
    "percentages = [count / sum(counts) * 100 for count in counts]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(labels, counts, edgecolor='black')\n",
    "plt.title('Class Distribution')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Annotate with percentage\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height + 5, f'{pct:.1f}%', \n",
    "             ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.ylim(0, max(counts) * 1.2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data \n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is your feature matrix of shape (num_samples, num_features)\n",
    "# and you decide on a sequence length\n",
    "sequence_length = 1  # Adjust based on your data\n",
    "input_size = X.shape[1] // sequence_length\n",
    "\n",
    "# Reshape X to (num_samples, sequence_length, input_size)\n",
    "X_reshaped = X.values.reshape(-1, sequence_length, input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input shape: torch.Size([3468, 1, 20])\n",
      "Val input shape:   torch.Size([867, 1, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Step 1: Reshape for RNN input â€” add a dummy sequence length dimension\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "# Step 2: Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Step 3: Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Step 4: Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Optional: check shapes\n",
    "print(f\"Train input shape: {X_train_tensor.shape}\")\n",
    "print(f\"Val input shape:   {X_test_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1, output_size=2):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # use last time step\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.5469 - Val Loss: 0.4312 - Val Acc: 0.7612\n",
      "Epoch 2/20 - Train Loss: 0.4238 - Val Loss: 0.4160 - Val Acc: 0.7647\n",
      "Epoch 3/20 - Train Loss: 0.4144 - Val Loss: 0.4116 - Val Acc: 0.7739\n",
      "Epoch 4/20 - Train Loss: 0.4092 - Val Loss: 0.4075 - Val Acc: 0.7716\n",
      "Epoch 5/20 - Train Loss: 0.4060 - Val Loss: 0.4052 - Val Acc: 0.7647\n",
      "Epoch 6/20 - Train Loss: 0.4031 - Val Loss: 0.4031 - Val Acc: 0.7774\n",
      "Epoch 7/20 - Train Loss: 0.4006 - Val Loss: 0.4026 - Val Acc: 0.7774\n",
      "Epoch 8/20 - Train Loss: 0.3953 - Val Loss: 0.4006 - Val Acc: 0.7785\n",
      "Epoch 9/20 - Train Loss: 0.3932 - Val Loss: 0.4014 - Val Acc: 0.7751\n",
      "Epoch 10/20 - Train Loss: 0.3900 - Val Loss: 0.4012 - Val Acc: 0.7762\n",
      "Epoch 11/20 - Train Loss: 0.3877 - Val Loss: 0.4012 - Val Acc: 0.7774\n",
      "Epoch 12/20 - Train Loss: 0.3872 - Val Loss: 0.4066 - Val Acc: 0.7774\n",
      "Epoch 13/20 - Train Loss: 0.3849 - Val Loss: 0.4051 - Val Acc: 0.7832\n",
      "Epoch 14/20 - Train Loss: 0.3825 - Val Loss: 0.4043 - Val Acc: 0.7751\n",
      "Epoch 15/20 - Train Loss: 0.3813 - Val Loss: 0.4069 - Val Acc: 0.7878\n",
      "Epoch 16/20 - Train Loss: 0.3788 - Val Loss: 0.4065 - Val Acc: 0.7785\n",
      "Epoch 17/20 - Train Loss: 0.3767 - Val Loss: 0.4077 - Val Acc: 0.7855\n",
      "Epoch 18/20 - Train Loss: 0.3747 - Val Loss: 0.4090 - Val Acc: 0.7855\n",
      "Epoch 19/20 - Train Loss: 0.3748 - Val Loss: 0.4107 - Val Acc: 0.7809\n",
      "Epoch 20/20 - Train Loss: 0.3712 - Val Loss: 0.4103 - Val Acc: 0.7924\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set hyperparameters\n",
    "input_size = X_train.shape[2]  # number of features\n",
    "hidden_size = 64\n",
    "num_layers = 1\n",
    "output_size = 2\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize model\n",
    "model = RNNModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "            _, preds = torch.max(val_outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(val_labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {sum(train_losses)/len(train_losses):.4f} \"\n",
    "          f\"- Val Loss: {sum(val_losses)/len(val_losses):.4f} - Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final Evaluation on Validation Set\n",
      "Confusion Matrix:\n",
      "[[484 113]\n",
      " [ 67 203]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control       0.88      0.81      0.84       597\n",
      "          PD       0.64      0.75      0.69       270\n",
      "\n",
      "    accuracy                           0.79       867\n",
      "   macro avg       0.76      0.78      0.77       867\n",
      "weighted avg       0.80      0.79      0.80       867\n",
      "\n",
      "AUC-ROC: 0.8696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get predicted class\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        # Get raw probabilities for AUC\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]  # PD = class 1\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Accuracy & report\n",
    "print(\"âœ… Final Evaluation on Validation Set\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Control\", \"PD\"]))\n",
    "\n",
    "# AUC\n",
    "auc_score = roc_auc_score(all_labels, all_probs)\n",
    "print(f\"AUC-ROC: {auc_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
